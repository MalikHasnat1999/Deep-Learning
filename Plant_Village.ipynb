{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant_Village.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "15VSFZyxhqwikL4biO0BKNaX9HvYq4Tqq",
      "authorship_tag": "ABX9TyPOOVFL6vzxPhXB0JWtKBYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MalikHasnat1999/Deep-Learning/blob/master/Plant_Village.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd5xIAXyHjCd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install -q kaggle"
      ],
      "metadata": {
        "id": "JmuwZX3HHw8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "metadata": {
        "id": "DkAqKBIvTEZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell if you can't find the kaggle folder\n",
        "# ! mkdir ~/.kaggle/    # make a kaggle folder in root directory"
      ],
      "metadata": {
        "id": "yiShSoEJTMPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy kaggle.json file to the kaggle folder in the root directory\n",
        "# !cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "_sGYmriETytW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the permissions of the .json file.\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "jcZNkPxXTzW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# That's all ! You can check if everything's okay by running this command\n",
        "# !kaggle datasets list "
      ],
      "metadata": {
        "id": "ifJlX7CrT3yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/spMohanty/PlantVillage-Dataset"
      ],
      "metadata": {
        "id": "zQvNFaNWT6Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install split-folders"
      ],
      "metadata": {
        "id": "VppvxC3hWW40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "input_folder = \"/content/PlantVillage-Dataset/raw/color\"\n",
        "splitfolders.ratio(input=input_folder,\n",
        "                   output=\"plants_dataset\",\n",
        "                   ratio=(0.8,0.2),\n",
        "                   seed=42)"
      ],
      "metadata": {
        "id": "QnpYiCIFV7cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/plants_dataset/train\" \n",
        "test_dir = \"/content/plants_dataset/val\" "
      ],
      "metadata": {
        "id": "Am6x-0-dXZaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting data from the Directory"
      ],
      "metadata": {
        "id": "1hDONmYCYm6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                    label_mode=\"categorical\",\n",
        "                                                                    image_size=(224,224))\n",
        "\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                   label_mode=\"categorical\",\n",
        "                                                                   image_size=(224,224),\n",
        "                                                                   shuffle=False) # don't shuffle test data for prediction analysis"
      ],
      "metadata": {
        "id": "cIIQH6RMXwce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get class_names\n",
        "class_names = train_dataset.class_names\n",
        "class_names, len(class_names)"
      ],
      "metadata": {
        "id": "rmdPsaxaZuc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the Data"
      ],
      "metadata": {
        "id": "hNL_69y5lJTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "def random_img(target_dir, target_class):\n",
        "  target_folder = target_dir + \"/\" + target_class\n",
        "  rand_img = random.sample(os.listdir(target_folder), 8)\n",
        "  plt.figure(figsize=(20,7))\n",
        "  for i in range(8):\n",
        "    img = mpimg.imread(target_folder + \"/\" + rand_img[i])\n",
        "    plt.subplot(2,4,i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(target_class)\n",
        "    plt.axis(\"off\")\n",
        "    print(f\"Shape: {img.shape}\")"
      ],
      "metadata": {
        "id": "YksGXvGEZ6MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_img(train_dir, random.choice(class_names))"
      ],
      "metadata": {
        "id": "EfKvLOWYlMql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Callbacks"
      ],
      "metadata": {
        "id": "aguWvset2jNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Checkpoint"
      ],
      "metadata": {
        "id": "NiB9YQ_I2m19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\"model_checkpoint\",\n",
        "                                                      save_weights_only=True,\n",
        "                                                      save_best_only=True,\n",
        "                                                      monitor=\"val_accuracy\")"
      ],
      "metadata": {
        "id": "C_DcfhKK2uYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Augmentation Layer"
      ],
      "metadata": {
        "id": "_nGaTjKly9PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_layer = tf.keras.Sequential([\n",
        "                tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "                tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "                tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
        "                tf.keras.layers.experimental.preprocessing.RandomWidth(0.2),\n",
        "                tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "                #tf.keras.layers.experimental.preprocessing.Rescaling(scale=1/255.) # not needed for EfficientNet\n",
        "\n",
        "], name=\"augmentation_layer\")"
      ],
      "metadata": {
        "id": "rWUtzNAczAM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1)Feature-Extraction"
      ],
      "metadata": {
        "id": "t1VN8lDJwqyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Without Augmentation)"
      ],
      "metadata": {
        "id": "q3jN2mvX3BY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# set up the base model\n",
        "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create model with functional API\n",
        "inputs = tf.keras.layers.Input(shape=(224,224,3), name=\"input_layer\")\n",
        "x = base_model(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_avg_pooling_layer\")(x)\n",
        "outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\", name=\"output_layer\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_featureExtraction_ENb7\")\n",
        "\n",
        "# compile the model\n",
        "model_1.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "    metrics= [\"accuracy\"]\n",
        ")\n",
        "\n",
        "# fit the model\n",
        "c = model_1.fit(train_dataset,\n",
        "                              epochs=5,\n",
        "                              steps_per_epoch=len(train_dataset),\n",
        "                              validation_data=test_dataset,\n",
        "                              validation_steps=int(0.15*len(test_dataset)),\n",
        "                              callbacks=[model_checkpoint])"
      ],
      "metadata": {
        "id": "5PrTpT0mlVS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "id": "FbfQ3wxf5R-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = model_1.evaluate(test_dataset)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "yA3Ghsg_68ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (With Augmentation)"
      ],
      "metadata": {
        "id": "RFcYmeP34PW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# set up the base model\n",
        "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# create model with functional API\n",
        "inputs = tf.keras.layers.Input(shape=(224,224,3), name=\"input_layer\")\n",
        "x = aug_layer(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_avg_pooling_layer\")(x)\n",
        "outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\", name=\"output_layer\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model_2.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# fit the model\n",
        "model_2_history = model_2.fit(train_dataset,\n",
        "                              epochs=5,\n",
        "                              steps_per_epoch=len(train_dataset),\n",
        "                              validation_data=test_dataset,\n",
        "                              validation_steps=int(0.15*(len(test_dataset))),\n",
        "                              callbacks=[model_checkpoint])"
      ],
      "metadata": {
        "id": "tq5afD9H3f3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "id": "l-iLj-WG67WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = model_2.evaluate(test_dataset)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "hgTGpMH47Usk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2)Fine-Tuning"
      ],
      "metadata": {
        "id": "S5ecNRvp7gFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(Without Augmentation)"
      ],
      "metadata": {
        "id": "49PIs_dgAEJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up base model\n",
        "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
        "# unfreeze all layers\n",
        "base_model.trainable = True\n",
        "\n",
        "# freeze all layers except for last 10\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "Z5BuA3HIJ_K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "  print(i,layer.name,layer.trainable)"
      ],
      "metadata": {
        "id": "cKB3-zBRADzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# create model using Functional API\n",
        "inputs = tf.keras.layers.Input(shape=(224,224,3), name=\"input_layer\")\n",
        "x = base_model(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\", name=\"output_layer\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model_3.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# fit the model\n",
        "model_3_history = model_3.fit(train_dataset,\n",
        "                              epochs=10,\n",
        "                              steps_per_epoch=len(train_dataset),\n",
        "                              validation_data=test_dataset,\n",
        "                              validation_steps=int(0.15*len(test_dataset)),\n",
        "                              initial_epoch=model_1_history.epoch[-1])"
      ],
      "metadata": {
        "id": "t3bm0JQE7fdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "y3e-AGWJVFwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (With Augmentation)"
      ],
      "metadata": {
        "id": "axQTkQUuWFwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model with functional API\n",
        "inputs = tf.keras.layers.Input(shape=(224,224,3), name=\"input_shape\")\n",
        "x = aug_layer(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model_4.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# fit the model\n",
        "model_4_history = model_4.fit(train_dataset,\n",
        "                              epochs=10,\n",
        "                              steps_per_epoch=len(train_dataset),\n",
        "                              validation_data=test_dataset,\n",
        "                              validation_steps=int(0.15*len(test_dataset)),\n",
        "                              initial_epoch=model_2_history.epoch[-1])"
      ],
      "metadata": {
        "id": "T2yJNTXqWFSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "xbuAYcx5bIjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.save(\"/content/drive/MyDrive/Saved_Models/PlantVillage-Dataset/Fine-tune-without-augmentation/ENb7\")"
      ],
      "metadata": {
        "id": "Kbn0_iyhw05h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.save(\"/content/drive/MyDrive/Saved_Models/PlantVillage-Dataset/Fine-tune-with-augmentation/ENb7.h5\")"
      ],
      "metadata": {
        "id": "_SoYI3PCyDMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model(\"/content/drive/MyDrive/Saved_Models/PlantVillage-Dataset/Fine-tune-with-augmentation/ENb7.h5\")"
      ],
      "metadata": {
        "id": "mpBgPwt6ZW5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "EO0D19ZybtoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_1 = tf.keras.models.load_model(\"/content/drive/MyDrive/Saved_Models/PlantVillage-Dataset/Fine-tune-without-augmentation/ENb7\")"
      ],
      "metadata": {
        "id": "9Ax-2910c7AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_1.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "nEOmJ1kmdd7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3)Scaling-up\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zw2MpJs62zw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the performance of our model across all different classes"
      ],
      "metadata": {
        "id": "WMeLWPTogtxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if loaded model is a trained model\n",
        "loaded_loss, loaded_accuracy = loaded_model_1.evaluate(test_dataset)\n",
        "loaded_loss, loaded_accuracy"
      ],
      "metadata": {
        "id": "9R2uoDoty4CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "pred_probs = loaded_model_1.predict(test_dataset, verbose=1) # set verbosity to see how long it will take "
      ],
      "metadata": {
        "id": "pLCJNOPMhuVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many predictions are there?\n",
        "len(pred_probs)"
      ],
      "metadata": {
        "id": "PBKd00MPiL1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the shape of our predictions?\n",
        "pred_probs.shape"
      ],
      "metadata": {
        "id": "r2HN_XeCndXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How do they look?\n",
        "pred_probs[:10]"
      ],
      "metadata": {
        "id": "0N4EYc4pmR5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We get one prediction probability per class\n",
        "print(f\"Number of prediction probabilities for sample 0: {len(pred_probs[0])}\")\n",
        "print(f\"What prediction probability sample 0 looks like:\\n {pred_probs[0]}\")\n",
        "print(f\"The class with the highest predicted probability by the model for sample 0: {pred_probs[0].argmax()}\")"
      ],
      "metadata": {
        "id": "2W5ats-EnICs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class predicitons of each label\n",
        "y_pred = pred_probs.argmax(axis=1)\n",
        "# How do they look?\n",
        "y_pred[:10]"
      ],
      "metadata": {
        "id": "Wgox8XnkiChc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: This might take a minute or so due to unravelling 790 batches\n",
        "y_labels = []\n",
        "for images, labels in test_dataset.unbatch(): # unbatch the test data and get images and labels\n",
        "  y_labels.append(labels.numpy().argmax()) # append the index which has the largest value (labels are one-hot)\n",
        "y_labels[:10] # check what they look like (unshuffled)"
      ],
      "metadata": {
        "id": "y5g-qm9f33Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating our models predictions"
      ],
      "metadata": {
        "id": "dyrFeI-Mj2Aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### accuracy_score()"
      ],
      "metadata": {
        "id": "p1UttN0AlUzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "sklearn_accuracy = accuracy_score(y_labels, y_pred)\n",
        "sklearn_accuracy"
      ],
      "metadata": {
        "id": "OBibbbOH-kZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### confusion_matrix()"
      ],
      "metadata": {
        "id": "LdYANwt4lM8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: The following confusion matrix code is a remix of Scikit-Learn's \n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "  \n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"  \n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "  \n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes), \n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "  \n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n",
        "  plt.xticks(rotation=70, fontsize=text_size)\n",
        "  plt.yticks(fontsize=text_size)\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")"
      ],
      "metadata": {
        "id": "Ze3KzACwlL2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_labels, y_pred, classes=class_names, figsize=(100,100))"
      ],
      "metadata": {
        "id": "h_bwD_0ylq3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_labels, y_pred))"
      ],
      "metadata": {
        "id": "a4yxjJus8mWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report_dict = classification_report(y_labels, y_pred, output_dict=True)\n",
        "classification_report_dict"
      ],
      "metadata": {
        "id": "5YS8WELt9mGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty dictionary\n",
        "class_f1_scores = {}\n",
        "# Loop through classification report items\n",
        "for k, v in classification_report_dict.items():\n",
        "  if k == \"accuracy\": # stop once we get to accuracy key\n",
        "    break\n",
        "  else:\n",
        "    # Append class names and f1-scores to new dictionary\n",
        "    class_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n",
        "class_f1_scores"
      ],
      "metadata": {
        "id": "wdMJyjhz96py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn f1-scores into dataframe for visualization\n",
        "import pandas as pd\n",
        "f1_scores = pd.DataFrame({\"class_name\": list(class_f1_scores.keys()),\n",
        "                          \"f1-score\": list(class_f1_scores.values())}).sort_values(\"f1-score\", ascending=False)\n",
        "f1_scores"
      ],
      "metadata": {
        "id": "009WAuGc-SP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 25))\n",
        "scores = ax.barh(range(len(f1_scores)), f1_scores[\"f1-score\"].values)\n",
        "ax.set_yticks(range(len(f1_scores)))\n",
        "ax.set_yticklabels(list(f1_scores[\"class_name\"]))\n",
        "ax.set_xlabel(\"f1-score\")\n",
        "ax.set_title(\"F1-Scores for 10 Different Classes\")\n",
        "ax.invert_yaxis(); # reverse the order\n",
        "\n",
        "def autolabel(rects): # Modified version of: https://matplotlib.org/examples/api/barchart_demo.html\n",
        "  \"\"\"\n",
        "  Attach a text label above each bar displaying its height (it's value).\n",
        "  \"\"\"\n",
        "  for rect in rects:\n",
        "    width = rect.get_width()\n",
        "    ax.text(1.03*width, rect.get_y() + rect.get_height()/1.5,\n",
        "            f\"{width:.2f}\",\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "autolabel(scores)"
      ],
      "metadata": {
        "id": "1Qe4yjqz-bOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q80lppU0-eYT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}